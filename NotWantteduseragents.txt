2ip bot 
80legs 
404checker 
Amazonbot 
amazonbot 
AhrefsBot 
AhrefsSiteAudit
BW/1.3
BW/1.2
BLEXBot
CensysInspect/1.1;
CyotekWebCopy
Cowboy 2.13
curl
DotBot
dotbot 
DataForSeoBot 
DomainStatsBot
Extreme Picture Finder
Go-http-client
Headless
HeadlessChrome 
Java-http-client
libwww 6.05
libwww-perl-6.77
MJ12bot
Nikto 
Ninja
Nmap 
Nuclei
Nutch
Nicecrawler/1.1
OnCrawl 
OpenVAS 
Python
python-http
python-requests
Python-urllib
python aiohttp
python-httpx
Prometheus 
Rogerbot 
SiteimproveBot-Crawler
SEOkicks
serpstatbot
Screaming Frog SEO Spider
SemrushBot 
SemrushBot-BA 
SemrushBot-SA 
SemrushBot-SI 
SemrushBot-SWA
SemrushBot-CT
SemrushBot-BM 
SemrushBot/7~bl 
SiteAuditBot      
SplitSignalBot   
SeoSiteCheckup 
SiteCheckerBotCrawler 
seobility 
TinEye 
TinEye-bot
TinEye-bot-live/1.31
TestNutchBot/0.1)/Nutch-1.21-SNAPSHOT
TikTokSpider
woorank
WPScan
WebImageCollector 
Wget
wget 
Web Image Collector 
Xenu 
Zeus 
Zgrab 
YaK
ZmEu 

..........................................
RAW FILE:

2ip bot|80legs|404checker 
Amazonbot|amazonbot|AhrefsBot| AhrefsSiteAudit|
BW/1.3|BW/1.2|BLEXBot|
CensysInspect/1.1;|CyotekWebCopy|Cowboy 2.13|curl|
DotBot|dotbot| DataForSeoBot|DomainStatsBot|
Extreme Picture Finder|
HeadlessChrome|Headless| 
Java-http-client|libwww 6.05|libwww-perl-6.77|
MJ12bot|Nikto|Ninja|Nmap Nuclei|Nutch|Nicecrawler/1.1|
OnCrawl|OpenVAS| 
Python|python-http|python-requests|Python-urllib|python aiohttp|python-httpx|Prometheus|Rogerbot| 
SiteimproveBot-Crawler|SEOkicks|serpstatbot|Screaming Frog SEO Spider|SemrushBot| SemrushBot-BA|SemrushBot-SA|SemrushBot/7~bl| 
SemrushBot-SI|SemrushBot-SWA|SemrushBot-CT|SemrushBot-BM|SiteAuditBot|SplitSignalBot|SeoSiteCheckup|SiteCheckerBotCrawler|seobility|
TinEye| TinEye-bot|TinEye-bot-live/1.31|TestNutchBot/0.1)/Nutch-1.21|TikTokSpider|
woorank|WPScan|WebImageCollector|libwww-perl|Wge|wget|Web Image Collector| 
Xenu|Zeus|Zgrab| YaK|ZmEu

*# Use of of my scripts - in Ai scrapers, if you not want theem pooking around!   ###'


:::::::::::::::::::::::::::::::::
250404:

# TikTokSpider
https://github.com/meetmr/TiktokSpider    //BOGUS Spider!!!!

::::::::::::::::::::::::::::::::::::::::::::::::

###SEARCH ENGINE CHINA:  //very aggresive:

RAW:
baidu|MicroMessenger
Weixin QQ|AspiegelBot|bytesdance|Bytespider|
Mb2345Browser|MQQBrowserLieBaoFast|Datanyze|
QQ Browser Mobile|Sogou|X Browser|115 Browser|
360 Browser|ChinaClaw|360Spider|petalbot|petalSearch|PetalBot|
;zh-cn|zh\-CN|zh_CN|zh-CN|ZHCN|zh|zh_CN|Openbot|zh|zh-CN|zh-SG|zh-TW|zh-HK|zh-CHS|zh-CHT|zhi-CN|ZHCN|zh-MO|
Haosou 360 spider|Sosospider|YisouSpider|YoudaoBot /|Test-Spider|testspider

#Aggresive china Terror:

chinamobile.com\.cn
chinamobile.com\.cn
chinatelecom.com\.cn
chinaunicom\.com 
chinaunicom\.cn
aliyun\.com 
alibaba\.com 
AliyunSecBot/Nutch-1.21-SNAPSHOT 
huawei\.com 

RAW:
chinamobile.com\.cn|chinamobile.com\.cn|chinatelecom.com\.cn|
chinaunicom\.com|chinaunicom\.cn|aliyun\.com|alibaba\.com|AliyunSecBot/Nutch-1.21-SNAPSHOT| huawei\.com 

......................................................
#Other not wanted:

RAW:

Apachebench|apache-auth|apache-bow-scanners|apache-scanners|apache-useragents|Apache-HttpClient|apache|
GuzzleHttp|GuzzleHttp/7|Go|Go1.1packagehttp|golang|Golang Scraper|Go Web Scraping||Go-http-client|
Go-http-client/1.1|Go-http-client/2.0|httplib|
SF|R|php|Prometheus|perl|libwww-perl|test|
python-async|python-requests|Python aiohttp|
python|python-httpx|PycURL|Python-urllibPython-urllib/3.8|Pyth|py|PyQ|
Apache-HttpClient/4.5.2 (Java/1.8.0_151|Java|urllib|
php://input|Zend_Http_Client|Wget


#No thanks!:

RAW:

ALittle Client|Headless scraping|HeadlessChrome|
CFNetwork|BLEXBot|DotBot|
DataForSeoBot|
GoogleScraper|Fetch|HtmlRequestScraper|Headless|Scan|headless.py|?p=[page_no]|
SSL/TLS Scan|SSL Scanner|tls-scan|scan|Replication Cockpit|
Rome Client|MJ12Bot|wp_is_mobile


::::::::::::::::::::::::::::::::::::::::::::::::
#  I USE:  (/.htaccess2: )

<IfModule mod_rewrite.c>
RewriteCond%{HTTP_USER_AGENT}"( | | | )"[NC]
RewriteRule !^/?robots\.txt$ - [F,L]
RewriteRule "^.*$" - [F,L]</IfModule>

::::::::::::::::::::::::::::::::::::::::::::::::
Updated: 250414




